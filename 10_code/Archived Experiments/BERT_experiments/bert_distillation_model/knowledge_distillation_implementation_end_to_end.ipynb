{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShLV9mW6_wQx"
      },
      "source": [
        "## Step 1: Creating a Knowledge Distillation Trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIdI7fuRAWIX"
      },
      "source": [
        "1. The new hyperparameters α and T\n",
        "α - control the relative weight of the distillation loss\n",
        "T - how much the probability distribution of the labels should be smoothed\n",
        "\n",
        "2. The fine-tuned teacher model, we will use BERT-base.\n",
        "\n",
        "3. A new loss function that combines the cross-entropy loss with the knowledge distillation loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOl95tzXA2-7"
      },
      "source": [
        "Adding the new hyperparameters is quite simple, since we just need to subclass TrainingArguments and include them as new attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XLxPXtH0_xnb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8YLJHHhA7jT"
      },
      "outputs": [],
      "source": [
        "class KnowledgeDistillationTrainingArguments(TrainingArguments):\n",
        "  def __init__(self, *args, alpha=0.5, temperature=2.0, **kwargs):\n",
        "    #*args allows us to pass a variable number of non-keyword arguments to a Python function.\n",
        "    #**kwargs stands for keyword arguments. The only difference from args is that it uses keywords and returns the values in the form of a dictionary.\n",
        "    super().__init__(*args, **kwargs)\n",
        "    #The super() function is often used with the __init__() method to initialize the attributes of the parent class.\n",
        "    self.alpha = alpha\n",
        "    self.temperature = temperature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QylIVtamlWBo"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jACpKjoRC3yi"
      },
      "source": [
        "#Lets code for new Loss Function\n",
        "We will subclass Trainer and overriding the compute_loss() method to include the knowledge distillation loss term LKD:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjHjc3e-B5Xf"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDsHhoN3DHkb"
      },
      "outputs": [],
      "source": [
        "class KnowledgeDistillationTrainer(Trainer):\n",
        "  def __init__(self, *args, teacher_model=None, **kwargs):\n",
        "    super().__init__(*args, **kwargs)\n",
        "    self.teacher_model = teacher_model\n",
        "\n",
        "  def compute_loss(self, model, inputs, return_outputs=False):\n",
        "    #Extract cross-entropy loss and logits from student\n",
        "    outputs_student = model(**inputs)\n",
        "    loss_ce = outputs_student.loss\n",
        "    logits_student = outputs_student.logits\n",
        "\n",
        "    # Extract logits from teacher\n",
        "    outputs_teacher = self.teacher_model(**inputs)\n",
        "    logits_teacher = outputs_teacher.logits\n",
        "\n",
        "     #Computing distillation loss by Softening probabilities\n",
        "    loss_fct = nn.KLDivLoss(reduction=\"batchmean\")\n",
        "    #The reduction=batchmean argument in nn.KLDivLoss() specifies that we average the losses over the batch dimension.\n",
        "    loss_kd = self.args.temperature ** 2 * loss_fct(\n",
        "                F.log_softmax(logits_student / self.args.temperature, dim=-1),\n",
        "                F.softmax(logits_teacher / self.args.temperature, dim=-1))\n",
        "\n",
        "    # Return weighted student loss\n",
        "    loss = self.args.alpha * loss_ce + (1. - self.args.alpha) * loss_kd\n",
        "    return (loss, outputs_student) if return_outputs else loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a60-qPkFWle"
      },
      "source": [
        "## Choosing a Good Student Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8niWzfzOFbSe"
      },
      "source": [
        "How to pick good student model?\n",
        "1. Smaller model than teacher for the student to reduce the latency and memory footprint\n",
        "\n",
        "2. Knowledge distillation functions best when the teacher and learner are of the same model type. (BERT and RoBERTa, can have different output embedding spaces which creates issues for student to mimic the teacher)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv8QmAHFGeQE"
      },
      "source": [
        "In this project, we will use DistilBERT. DistilBERT is a natural candidate to initialize the student with since it has 40% fewer parameters and has been shown to achieve strong results on downstream tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KNDvBb0G7Ie"
      },
      "source": [
        "### Lets load dataset first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaP8QeMrHBCo"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYQfNSWbEMj0"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8r-jEL4Hm4M"
      },
      "source": [
        "We will use CLINC150 dataset which is used to solve the problem of Intent Classification\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08NzJ3g6HksW"
      },
      "outputs": [],
      "source": [
        "clinc = load_dataset(\"clinc_oos\", \"plus\")\n",
        "#the plus configuration refers to the subset that contains the out-of-scope training examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxloSRf8HvZ5"
      },
      "outputs": [],
      "source": [
        "sample = clinc[\"train\"][0]\n",
        "print(sample)\n",
        "#Each example in the CLINC150 dataset consists of a query in the text column and its corresponding intent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPq0YTLrH7oj"
      },
      "source": [
        "The intents are provided as IDs, but we can easily get the mapping to strings (and vice versa) by accessing the features attribute of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJEaBRWpHzWo"
      },
      "outputs": [],
      "source": [
        "    intents = clinc[\"train\"].features[\"intent\"]\n",
        "    intent = intents.int2str(sample[\"intent\"])\n",
        "    print(intent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_pHhDuMILnc"
      },
      "source": [
        "#Lets preprocess or tokenize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kxUuVeHH5r0"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7kEoYAoIPwF"
      },
      "outputs": [],
      "source": [
        "student_checkpoint = \"distilbert-base-uncased\"\n",
        "student_tokenizer = AutoTokenizer.from_pretrained(student_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e71qdL6xIT3m"
      },
      "outputs": [],
      "source": [
        "def tokenize_text(batch):\n",
        "  return student_tokenizer(batch[\"text\"], truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zP064S4sIa6H"
      },
      "outputs": [],
      "source": [
        "clinc_tokenized = clinc.map(tokenize_text, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "#We will remove text column as we don't need it\n",
        "#We will also rename the intent column to labels so it can be automatically detected by the trainer.\n",
        "clinc_tokenized = clinc_tokenized.rename_column(\"intent\", \"labels\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fSUsRbgKHq7"
      },
      "source": [
        "#Lets define metrics for DistillationTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpUI6EZiKK-p"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "accuracy_score = load_metric(\"accuracy\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  predictions, labels = pred\n",
        "  predictions = np.argmax(predictions, axis=1)\n",
        "  return accuracy_score.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNXBLatvKcmv"
      },
      "source": [
        "In this function, the predictions from the sequence modeling head come in the form of logits, so we use the np.argmax() function to find the most confident class predic‐ tion and compare that against the ground truth label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jI9609N3LnA7"
      },
      "outputs": [],
      "source": [
        "!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi074k0aKgdm"
      },
      "source": [
        "#Lets define Training Arguments for DistillationTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jh-LFz3QKS0Q"
      },
      "outputs": [],
      "source": [
        "batch_size = 48\n",
        "finetuned_student_ckpt = \"distilbert-base-uncased-finetuned-clinc-student\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kqDWLqhL7jk"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate>=0.20.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7epVe7uKmBb"
      },
      "outputs": [],
      "source": [
        "student_training_args = KnowledgeDistillationTrainingArguments(\n",
        "    output_dir=finetuned_student_ckpt, evaluation_strategy = \"epoch\",\n",
        "    num_train_epochs=1, learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size, alpha=1, weight_decay=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-DTzbcvNLdX"
      },
      "source": [
        "## Lets initialize student model but before that provide the student model with the mappings between each intent and label ID."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXrAiUxnKv1v"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "bert_ckpt = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
        "pipe = pipeline(\"text-classification\", model=bert_ckpt)\n",
        "\n",
        "id2label = pipe.model.config.id2label\n",
        "label2id = pipe.model.config.label2id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q5mVIMzNTry"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoConfig\n",
        "num_labels = intents.num_classes\n",
        "student_config = (AutoConfig\n",
        "                  .from_pretrained(student_checkpoint, num_labels=num_labels,\n",
        "                                    id2label=id2label, label2id=label2id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5ntdpKzPF20"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "def student_init():\n",
        "  return (AutoModelForSequenceClassification.from_pretrained(student_checkpoint, config=student_config).to(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_pwSM8aPb4r"
      },
      "source": [
        "## Lets Load teacher checkpoint and start finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfZFhd-_PVCX"
      },
      "outputs": [],
      "source": [
        "teacher_checkpoint = \"transformersbook/bert-base-uncased-finetuned-clinc\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RljObrzrPlKx"
      },
      "outputs": [],
      "source": [
        "teacher_model = (AutoModelForSequenceClassification\n",
        "                     .from_pretrained(teacher_checkpoint, num_labels=num_labels)\n",
        "                     .to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-vXAa1iPqJ9"
      },
      "outputs": [],
      "source": [
        "#Lets start the training\n",
        "distilbert_trainer = KnowledgeDistillationTrainer(model_init=student_init,\n",
        "        teacher_model=teacher_model, args=student_training_args,\n",
        "        train_dataset=clinc_tokenized['train'], eval_dataset=clinc_tokenized['validation'],\n",
        "        compute_metrics=compute_metrics, tokenizer=student_tokenizer)\n",
        "distilbert_trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKOilJSN-M3d"
      },
      "source": [
        "## Lets compare Teacher and Student Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2BX_vmsQU2a"
      },
      "outputs": [],
      "source": [
        "#We will compare the two models based on size and inference time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbgDGiD7IWHf"
      },
      "source": [
        "Saving Teacher and Student model and then computing model's size in MB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tY0C3ZsdIVaK"
      },
      "outputs": [],
      "source": [
        "def save_teacher_model():\n",
        "  teacher_model.save_pretrained(\"teacher_model\")\n",
        "def save_student_model():\n",
        "  distilbert_trainer.save_model('student_model')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DU0EuD7UI9ji"
      },
      "outputs": [],
      "source": [
        "save_teacher_model()\n",
        "save_student_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7LJRPRzJkOg"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
        "import os\n",
        "\n",
        "def compute_parameters(model_path):\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "  parameters = model.num_parameters()\n",
        "  return parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-leprTuIE2w"
      },
      "outputs": [],
      "source": [
        "teacher_model_parameters = compute_parameters(model_path=\"/content/teacher_model\")\n",
        "print(\"Teacher Model: \", teacher_model_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Plfdn76CLKVS"
      },
      "outputs": [],
      "source": [
        "student_model_parameters = compute_parameters(model_path=\"/content/student_model\")\n",
        "print(\"Student Model: \", student_model_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHRy48NBNPV3"
      },
      "outputs": [],
      "source": [
        "decrease = (student_model_parameters-teacher_model_parameters)/teacher_model_parameters\n",
        "print(decrease*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQsbyCP7Lfgc"
      },
      "outputs": [],
      "source": [
        "!ls /content/student_model -al --block-size=MB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPduu_l7MZeg"
      },
      "outputs": [],
      "source": [
        "!ls /content/teacher_model -al --block-size=MB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Og3MC2FOMh_S"
      },
      "outputs": [],
      "source": [
        "print(clinc['train']['text'][101])\n",
        "print(clinc['train']['intent'][101])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hhz7qrUoNzJ0"
      },
      "outputs": [],
      "source": [
        "#we will take average times of multiple inferences on same input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22AhklIhOEFL"
      },
      "outputs": [],
      "source": [
        "#Lets warmup first\n",
        "from transformers import pipeline\n",
        "import time\n",
        "\n",
        "pipe = pipeline(\"text-classification\", model=\"/content/teacher_model\", tokenizer='bert-base-uncased')\n",
        "\n",
        "sample_input = clinc['train']['text'][101]\n",
        "\n",
        "#WARMUP\n",
        "for _ in range(10):\n",
        "  _ = pipe(sample_input)\n",
        "\n",
        "start = time.time()\n",
        "for _ in range(100):\n",
        "  _ = pipe(sample_input)\n",
        "total_time_teacher_model = time.time()-start\n",
        "print(\"Total time to process 100 requests for Teacher Model: \",total_time_teacher_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ND0Rk_c-Od-s"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\"text-classification\", model=\"/content/student_model\", tokenizer=\"distilbert-base-uncased\")\n",
        "\n",
        "sample_input = clinc['train']['text'][101]\n",
        "\n",
        "#WARMUP\n",
        "for _ in range(10):\n",
        "  _ = pipe(sample_input)\n",
        "\n",
        "start = time.time()\n",
        "for _ in range(100):\n",
        "  _ = pipe(sample_input)\n",
        "total_time_student_model = time.time()-start\n",
        "\n",
        "print(\"Total time to process 100 requests for Student Model: \",total_time_student_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XkDVWpQnHK-"
      },
      "outputs": [],
      "source": [
        "decrease_in_time = (total_time_teacher_model-total_time_student_model)/total_time_teacher_model\n",
        "print(decrease_in_time*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2EMVqOEoFYQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
