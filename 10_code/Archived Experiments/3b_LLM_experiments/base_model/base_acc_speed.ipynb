{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset human-vs-machine (/home/codespace/.cache/huggingface/datasets/NicolaiSivesind___human-vs-machine/research_abstracts_labeled/0.0.0/9e9ff0b78fa974ae55166fbed3b9032d432c39f2e76909d68bdd53cb4ea313de)\n",
      "100%|██████████| 3/3 [00:00<00:00, 659.03it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.09s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dataset = load_dataset(\"NicolaiSivesind/human-vs-machine\", \"research_abstracts_labeled\")['test'][0:50]\n",
    "x_test, y_test = dataset['text'], dataset['label']\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"andreas122001/bloomz-3b-wiki-detector\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"andreas122001/bloomz-3b-wiki-detector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 11453.867MB\n"
     ]
    }
   ],
   "source": [
    "param_size = 0\n",
    "for param in model.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in model.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "base_model_size = (param_size + buffer_size) / 1024**2\n",
    "print('Model size: {:.3f}MB'.format(base_model_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 1, 1, 1, 0, 0, 1, 1]\n",
      "[3.0076465606689453, 2.563746690750122, 7.519760847091675, 4.173773765563965, 9.64520001411438, 6.830012559890747, 4.011502742767334, 3.0249407291412354, 1.7653095722198486, 1.77117919921875]\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "times = []\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "for idx, text in enumerate(x_test):\n",
    "    input = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    st = time.time()\n",
    "    output = model(**input).logits\n",
    "    predicted_class = torch.argmax(output).item()\n",
    "    y_pred.append(predicted_class)\n",
    "    times.append(time.time() - st)\n",
    "\n",
    "print(y_pred)\n",
    "print(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = [0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1]\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    50.000000\n",
       "mean      5.203698\n",
       "std       2.606995\n",
       "min       1.391731\n",
       "25%       3.009356\n",
       "50%       5.173841\n",
       "75%       7.184355\n",
       "max      12.174996\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = pd.Series([3.899423122406006, 3.0144855976104736, 8.07302212715149, 6.465184926986694, 3.150974988937378, 2.902872085571289, 6.113534450531006, 5.451525926589966, 8.014659643173218, 5.68673038482666, \n",
    "                  1.4908013343811035, 1.391730785369873, 7.938936948776245, 7.7671730518341064, 7.570752382278442, 6.162149667739868, 7.994791507720947, 6.498159170150757, 7.302468538284302, 5.080890655517578, \n",
    "                4.976664781570435, 2.71449613571167, 2.98722767829895, 2.6232614517211914, 11.119134187698364, 5.91392183303833, 6.074051141738892, 5.266791105270386, 7.89971923828125, 6.698412895202637, \n",
    "                 12.17499589920044, 8.233731031417847, 6.3944008350372314, 4.704039573669434, 3.8241074085235596, 3.3292598724365234, 1.5289897918701172, 1.7963066101074219, 3.070106029510498, 2.5719656944274902, \n",
    "                  3.0076465606689453, 2.563746690750122, 7.519760847091675, 4.173773765563965, 9.64520001411438, 6.830012559890747, 4.011502742767334, 3.0249407291412354, 1.7653095722198486, 1.77117919921875])\n",
    "                 \n",
    "times.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
